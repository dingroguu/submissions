{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from math import log10, sqrt \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def load_images_from_folder(foldername, target_size=(64, 64)):\n",
    "    images = []\n",
    "    for filename in os.listdir(foldername):\n",
    "        img = cv.imread(os.path.join(foldername, filename), cv.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv.resize(img, target_size)  \n",
    "            images.append(img)\n",
    "    return images\n",
    "# https://stackoverflow.com/questions/66471454/how-to-read-images-from-our-system-folder-to-jupyter-notebook-python-file\n",
    "\n",
    "# Load images\n",
    "images=load_images_from_folder(\"pneumonia\")\n",
    "images = np.array(images)\n",
    "images = images.astype('float32') / 255.\n",
    "images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "lam25noise = np.random.poisson(25, images.shape)\n",
    "lam25 = images + lam25noise\n",
    "\n",
    "lam50noise = np.random.poisson(50, images.shape)\n",
    "lam50 = images + lam50noise\n",
    "\n",
    "lam75noise = np.random.poisson(75, images.shape)\n",
    "lam75 = images + lam75noise\n",
    "# https://stackoverflow.com/questions/19289470/adding-poisson-noise-to-an-image\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "x_train, x_test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "train25, test25 = train_test_split(lam25, test_size=0.2, random_state=42)\n",
    "train50, test50 = train_test_split(lam50, test_size=0.2, random_state=42)\n",
    "train75, test75 = train_test_split(lam75, test_size=0.2, random_state=42)\n",
    "\n",
    "def PSNR(original, compressed):\n",
    "    original = tf.cast(original, tf.float32)\n",
    "    compressed = tf.cast(compressed, tf.float32)      \n",
    "    mse = tf.reduce_mean(tf.square(original - compressed))\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * tf.math.log(max_pixel / tf.sqrt(mse)) / tf.math.log(10.0)\n",
    "\n",
    "    return psnr \n",
    "# PSNR function from previous submission, modified for Tensor use \n",
    "\n",
    "input_img = Input(shape=(64, 64, 1))  \n",
    "\n",
    "def forward(input):\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "   \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    return decoded\n",
    "     # https://www.tensorflow.org/api_docs/python/tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 5s 344ms/step - loss: 53.5378 - val_loss: 53.5676\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 5s 331ms/step - loss: 53.5208 - val_loss: 53.5676\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 53.5214 - val_loss: 53.5676\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 53.5208 - val_loss: 53.5676\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 53.5206 - val_loss: 53.5676\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 53.5707\n",
      "PSNR: 53.57073974609375\n"
     ]
    }
   ],
   "source": [
    "model25 = Model(input_img, forward(input_img))\n",
    "model25.compile(optimizer='adam', loss=PSNR)\n",
    "\n",
    "model25.fit(train25, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test25, x_test))\n",
    "\n",
    "psnr25 = model25.evaluate(test25, x_test)\n",
    "print(\"PSNR:\", psnr25)\n",
    "#https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 5s 299ms/step - loss: 53.0503 - val_loss: 52.9975\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 53.0395 - val_loss: 52.9975\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 53.0395 - val_loss: 52.9975\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 53.0391 - val_loss: 52.9975\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 5s 327ms/step - loss: 53.0398 - val_loss: 52.9975\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 52.9998\n",
      "PSNR: 52.999839782714844\n"
     ]
    }
   ],
   "source": [
    "model50 = Model(input_img, forward(input_img))\n",
    "model50.compile(optimizer='adam', loss=PSNR)\n",
    "\n",
    "model50.fit(train50, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test50, x_test))\n",
    "\n",
    "psnr50 = model50.evaluate(test50, x_test)\n",
    "print(\"PSNR:\", psnr50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 53.0660 - val_loss: 52.9975\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 5s 346ms/step - loss: 53.0396 - val_loss: 52.9975\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 5s 322ms/step - loss: 53.0394 - val_loss: 52.9975\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 5s 333ms/step - loss: 53.0399 - val_loss: 52.9975\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 5s 343ms/step - loss: 53.0400 - val_loss: 52.9975\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 52.9998\n",
      "PSNR: 52.999839782714844\n"
     ]
    }
   ],
   "source": [
    "model75 = Model(input_img, forward(input_img))\n",
    "model75.compile(optimizer='adam', loss=PSNR)\n",
    "\n",
    "model75.fit(train75, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test75, x_test))\n",
    "\n",
    "psnr75 = model75.evaluate(test75, x_test)\n",
    "print(\"PSNR:\", psnr75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.12184\n",
      "31.114208\n",
      "29.364433\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in test25:\n",
    "        for n in range(1, 31, 2):\n",
    "                blur25 = cv.blur(test25[x], (n,n))\n",
    "                blur50 = cv.blur(test50[x], (n,n))\n",
    "                blur75 = cv.blur(test75[x], (n,n))\n",
    "        x+=1\n",
    "\n",
    "\n",
    "psnr_blur25 = PSNR(test25, blur25)\n",
    "psnr_blur25 = np.mean(psnr_blur25)\n",
    "print (psnr_blur25)\n",
    "\n",
    "psnr_blur50 = PSNR(test50, blur50)\n",
    "psnr_blur50 = np.mean(psnr_blur50)\n",
    "print (psnr_blur50)\n",
    "\n",
    "psnr_blur75 = PSNR(test75, blur75)\n",
    "psnr_blur75 = np.mean(psnr_blur75)\n",
    "print (psnr_blur75)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.032207\n",
      "31.050962\n",
      "29.305325\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in test25:\n",
    "        for n in range(1, 31, 2):\n",
    "                src25 =test25[x].astype(np.uint8)\n",
    "                src50 = test50[x].astype(np.uint8)\n",
    "                src75 = test75[x].astype(np.uint8)\n",
    "                medBlur25 = cv.medianBlur(src25, n)\n",
    "                medBlur50 = cv.medianBlur(src50, n)\n",
    "                medBlur75 = cv.medianBlur(src75, n)\n",
    "        x+=1\n",
    "\n",
    "psnr_medBlur25 = PSNR(test25, medBlur25)\n",
    "psnr_medBlur25 = np.mean(psnr_medBlur25)\n",
    "print (psnr_medBlur25)\n",
    "\n",
    "psnr_medBlur50 = PSNR(test50, medBlur50)\n",
    "psnr_medBlur50 = np.mean(psnr_medBlur50)\n",
    "print (psnr_medBlur50)\n",
    "\n",
    "psnr_medBlur75 = PSNR(test75, medBlur75)\n",
    "psnr_medBlur75 = np.mean(psnr_medBlur75)\n",
    "print (psnr_medBlur75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.09472\n",
      "31.075706\n",
      "29.330585\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in test25:\n",
    "        for n in range(1, 31, 2):\n",
    "                src25 =test25[x].astype(np.uint8)\n",
    "                src50 = test50[x].astype(np.uint8)\n",
    "                src75 = test75[x].astype(np.uint8)\n",
    "                bilateral25 = cv.bilateralFilter(src25, n, n * 2, n / 2)\n",
    "                bilateral50 = cv.bilateralFilter(src50, n, n * 2, n / 2)\n",
    "                bilateral75 = cv.bilateralFilter(src75, n, n * 2, n / 2)\n",
    "        x += 1\n",
    "\n",
    "psnr_bilateral25 = PSNR(test25, bilateral25)\n",
    "psnr_bilateral25 = np.mean(psnr_bilateral25)\n",
    "print (psnr_bilateral25)\n",
    "\n",
    "psnr_bilateral50 = PSNR(test50, bilateral50)\n",
    "psnr_bilateral50 = np.mean(psnr_bilateral50)\n",
    "print (psnr_bilateral50)\n",
    "\n",
    "psnr_bilateral75 = PSNR(test75, bilateral75)\n",
    "psnr_bilateral75 = np.mean(psnr_bilateral75)\n",
    "print (psnr_bilateral75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.073586\n",
      "31.052164\n",
      "29.320675\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for i in test25:\n",
    "    for n in range(1, 31, 2):\n",
    "        src25 =test25[x].astype(np.uint8)\n",
    "        src50 = test50[x].astype(np.uint8)\n",
    "        src75 = test75[x].astype(np.uint8)\n",
    "        gaussian25 = cv.GaussianBlur(src25, (n, n), 0)\n",
    "        gaussian50 = cv.GaussianBlur(src50, (n, n), 0)\n",
    "        gaussian75 = cv.GaussianBlur(src75, (n, n), 0)        \n",
    "    x += 1\n",
    "\n",
    "psnr_gaussian25 = PSNR(test25, gaussian25)\n",
    "psnr_gaussian25 = np.mean(psnr_gaussian25)\n",
    "print (psnr_gaussian25)\n",
    "\n",
    "psnr_gaussian50 = PSNR(test50, gaussian50)\n",
    "psnr_gaussian50 = np.mean(psnr_gaussian50)\n",
    "print (psnr_gaussian50)\n",
    "\n",
    "psnr_gaussian75 = PSNR(test75, gaussian75)\n",
    "psnr_gaussian75 = np.mean(psnr_gaussian75)\n",
    "print (psnr_gaussian75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tLambda = 25 \t\tLambda = 50 \t\tLambda = 75\n",
      "Median Filter\t\t 34.032207 \t\t 31.050962 \t\t 29.305325\n",
      "Mean Filter\t\t 34.12184 \t\t 31.114208 \t\t 29.364433\n",
      "Bilateral Filter\t 34.09472 \t\t 31.075706 \t\t 29.330585\n",
      "Gaussian Filter\t\t 34.073586 \t\t 31.052164 \t\t 29.320675\n",
      "Autoencoder Model\t 53.57073974609375 \t 52.999839782714844 \t 52.999839782714844\n"
     ]
    }
   ],
   "source": [
    "autoencoder_lambdas = [25, 50, 75]\n",
    "\n",
    "print(\"\\t\\t\\tLambda =\", autoencoder_lambdas[0], \"\\t\\tLambda =\", autoencoder_lambdas[1], \"\\t\\tLambda =\", autoencoder_lambdas[2])\n",
    "print(\"Median Filter\\t\\t\", psnr_medBlur25, \"\\t\\t\", psnr_medBlur50, \"\\t\\t\", psnr_medBlur75)\n",
    "print(\"Mean Filter\\t\\t\", psnr_blur25, \"\\t\\t\", psnr_blur50, \"\\t\\t\", psnr_blur75)\n",
    "print(\"Bilateral Filter\\t\", psnr_bilateral25, \"\\t\\t\", psnr_bilateral50, \"\\t\\t\", psnr_bilateral75)\n",
    "print(\"Gaussian Filter\\t\\t\", psnr_gaussian25, \"\\t\\t\", psnr_gaussian50, \"\\t\\t\", psnr_gaussian75)\n",
    "print(\"Autoencoder Model\\t\", psnr25, \"\\t\", psnr50, \"\\t\", psnr75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Why is poisson distribution the ideal one to use to simulate noise for medical images? Why not gaussian or something else? Answer in terms of relevance of medical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson distribution is ideal since the noise it models is not additive. Poisson noise is signal dependent which means it can capture better the effect of the light in the photograph which is what causes noise. The nature of poisson distribution, which counts events over a period of time also reflects the interaction between the photon beams and certain parts of the body; determining which areas recieved low or high photons.\n",
    "\n",
    "https://www.proquest.com/openview/e96ddb9f4d6900580e8354a09ff5ff98/1?pq-origsite=gscholar&cbl=1616336"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Which one performed the best? Why do you think this is the case?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the average PSNR loss values provided:\n",
    "\n",
    "- For Lambda = 25, the autoencoder model performed the best with a PSNR of 53.57\n",
    "- For Lambda = 50, the autoencoder model performed the best with a PSNR of 52.99\n",
    "- For Lambda = 75, the autoencoder model performed the best with a PSNR of 52.99.\n",
    "\n",
    "The autoencoder model performed the best across all Lambda values. Unlike classical methods such as the Median, Mean, Bilateral, and Gaussian filtering––which apply fixed rules to filter noise––autoencoders adaptively learn from the noisy data during training. This allows them to outperform classical methods, especially when dealing with varying noise distributions or characteristics in the data. Consequently, the autoencoder model achieved higher PSNR values and a lower PSNR loss, indicating signs of superior denoising performance compared to the aforementioned classical methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
