{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from math import log10, sqrt \n",
    "import tensorflow as tf\n",
    "\n",
    "def load_images_from_folder(foldername, target_size=(64, 64)):\n",
    "    images = []\n",
    "    for filename in os.listdir(foldername):\n",
    "        img = cv.imread(os.path.join(foldername, filename), cv.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            img = cv.resize(img, target_size)  \n",
    "            images.append(img)\n",
    "    return images\n",
    "# https://stackoverflow.com/questions/66471454/how-to-read-images-from-our-system-folder-to-jupyter-notebook-python-file\n",
    "\n",
    "# PSNR function from previous submission, modified for Tensor use \n",
    "def PSNR(original, compressed):\n",
    "    original = tf.cast(original, tf.float32)\n",
    "    compressed = tf.cast(compressed, tf.float32)      \n",
    "    mse = tf.reduce_mean(tf.square(original - compressed))\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * tf.math.log(max_pixel / tf.sqrt(mse)) / tf.math.log(10.0)\n",
    "\n",
    "    return psnr \n",
    "\n",
    "input_img = Input(shape=(64, 64, 1))  \n",
    "\n",
    "def encode (input):\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    return encoded\n",
    "\n",
    "def forward(input):\n",
    "    encoded = encode(input)\n",
    "   \n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    return decoded\n",
    "    # https://www.tensorflow.org/api_docs/python/tf\n",
    "\n",
    "# Build autoencoder model\n",
    "autoencoder = Model(input_img, forward(input_img))\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "# Load images\n",
    "images=load_images_from_folder(\"pneumonia\")\n",
    "images = np.array(images)\n",
    "images = images.astype('float32') / 255.\n",
    "images = np.expand_dims(images, axis=-1)\n",
    "\n",
    "# Generate noisy images\n",
    "lam25noise = np.random.poisson(25, images.shape)\n",
    "lam25 = images + lam25noise\n",
    "\n",
    "lam50noise = np.random.poisson(50, images.shape)\n",
    "lam50 = images + lam50noise\n",
    "\n",
    "lam75noise = np.random.poisson(75, images.shape)\n",
    "lam75 = images + lam75noise\n",
    "# https://stackoverflow.com/questions/19289470/adding-poisson-noise-to-an-image\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "x_train, x_test = train_test_split(images, test_size=0.2, random_state=42)\n",
    "train25, test25 = train_test_split(lam25, test_size=0.2, random_state=42)\n",
    "train50, test50 = train_test_split(lam50, test_size=0.2, random_state=42)\n",
    "train75, test75 = train_test_split(lam75, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 5s 246ms/step - loss: 0.0425 - val_loss: 0.0253\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 4s 236ms/step - loss: 0.0192 - val_loss: 0.0117\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 4s 245ms/step - loss: 0.0093 - val_loss: 0.0074\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 4s 278ms/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 5s 326ms/step - loss: 0.0057 - val_loss: 0.0051\n",
      "15/15 [==============================] - 1s 28ms/step\n",
      "Average PSNR for lambda 25 validation images: 20.164845\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_img, forward(input_img))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(x_train, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))\n",
    "\n",
    "\n",
    "encoded_images = encode(x_train)\n",
    "encoded_images = tf.reshape(encoded_images, [-1])\n",
    "\n",
    "np.savetxt(\"encoded_images.csv\", encoded_images, delimiter=\",\")\n",
    "\n",
    "# Validation PSNR for lambda 25\n",
    "decoded_images_25 = model.predict(test25) \n",
    "psnr_25 = PSNR(test25, decoded_images_25)\n",
    "print(\"Average PSNR for lambda 25 validation images:\", np.mean(psnr_25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 5s 342ms/step - loss: 0.1598 - val_loss: 0.0463\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.0389 - val_loss: 0.0361\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.0339 - val_loss: 0.0319\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 0.0322 - val_loss: 0.0313\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 0.0319 - val_loss: 0.0312\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.0312\n",
      "PSNR: 0.031163414940238\n",
      "15/15 [==============================] - 0s 22ms/step\n",
      "Average PSNR for lambda 25 validation images: 19.99965\n"
     ]
    }
   ],
   "source": [
    "model25 = Model(input_img, forward(input_img))\n",
    "model25.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model25.fit(train25, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test25, x_test))\n",
    "\n",
    "psnr25 = model25.evaluate(test25, x_test)\n",
    "print(\"PSNR:\", psnr25)\n",
    "\n",
    "encoded_images_noisy = []\n",
    "for image in train25:  \n",
    "    encoded_image = encode(np.expand_dims(image, axis=0)) \n",
    "    encoded_image_flat = np.array(encoded_image).flatten() \n",
    "    encoded_images_noisy.append(encoded_image_flat)\n",
    "\n",
    "encoded_images_noisy = np.array(encoded_images_noisy)\n",
    "\n",
    "np.savetxt(\"encoded_images_lam25.csv\", encoded_images_noisy, delimiter=\",\")\n",
    "\n",
    "# Validation PSNR for lambda 25\n",
    "decoded_images_25 = model25.predict(test25) \n",
    "psnr_25 = PSNR(test25, decoded_images_25)\n",
    "print(\"Average PSNR for lambda 25 validation images:\", np.mean(psnr_25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 0.2788 - val_loss: 0.2783\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 5s 342ms/step - loss: 0.2807 - val_loss: 0.2774\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 5s 302ms/step - loss: 0.2802 - val_loss: 0.2772\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 5s 302ms/step - loss: 0.2801 - val_loss: 0.2772\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 5s 301ms/step - loss: 0.2801 - val_loss: 0.2771\n",
      "15/15 [==============================] - 0s 20ms/step - loss: 0.2771\n",
      "PSNR: 0.27712565660476685\n",
      "15/15 [==============================] - 0s 21ms/step\n",
      "Average PSNR for lambda 50 validation images: 13.9863615\n"
     ]
    }
   ],
   "source": [
    "model50 = Model(input_img, forward(input_img))\n",
    "model50.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model50.fit(train50, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test50, x_test))\n",
    "\n",
    "psnr50 = model50.evaluate(test50, x_test)\n",
    "print(\"PSNR:\", psnr50)\n",
    "\n",
    "encoded_images_noisy = []\n",
    "for image in train50:  \n",
    "    encoded_image = encode(np.expand_dims(image, axis=0)) \n",
    "    encoded_image_flat = np.array(encoded_image).flatten() \n",
    "    encoded_images_noisy.append(encoded_image_flat)\n",
    "\n",
    "encoded_images_noisy = np.array(encoded_images_noisy)\n",
    "\n",
    "np.savetxt(\"encoded_images_lam50.csv\", encoded_images_noisy, delimiter=\",\")\n",
    "\n",
    "# Validation PSNR for lambda 50\n",
    "decoded_images_50 = model50.predict(test50)  \n",
    "psnr_50 = PSNR(test50, decoded_images_50)\n",
    "print(\"Average PSNR for lambda 50 validation images:\", np.mean(psnr_50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 0.0660 - val_loss: 0.0345\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 4s 299ms/step - loss: 0.0340 - val_loss: 0.0319\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 5s 302ms/step - loss: 0.0322 - val_loss: 0.0312\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 0.0317 - val_loss: 0.0310\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 5s 296ms/step - loss: 0.0316 - val_loss: 0.0309\n",
      "15/15 [==============================] - 0s 19ms/step - loss: 0.0309\n",
      "PSNR: 0.030855482444167137\n",
      "15/15 [==============================] - 0s 20ms/step\n",
      "Average PSNR for lambda 75 validation images: 10.519686\n"
     ]
    }
   ],
   "source": [
    "model75 = Model(input_img, forward(input_img))\n",
    "model75.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "model75.fit(train75, x_train,\n",
    "                epochs=5,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(test75, x_test))\n",
    "\n",
    "psnr75 = model75.evaluate(test75, x_test)\n",
    "print(\"PSNR:\", psnr75)\n",
    "\n",
    "encoded_images_noisy = []\n",
    "for image in train75:  \n",
    "    encoded_image = encode(np.expand_dims(image, axis=0)) \n",
    "    encoded_image_flat = np.array(encoded_image).flatten() \n",
    "    encoded_images_noisy.append(encoded_image_flat)\n",
    "\n",
    "encoded_images_noisy = np.array(encoded_images_noisy)\n",
    "np.savetxt(\"encoded_images_lam75.csv\", encoded_images_noisy, delimiter=\",\")\n",
    "\n",
    "# Validation PSNR for lambda 75\n",
    "decoded_images_75 = model50.predict(test75)  \n",
    "psnr_75 = PSNR(test75, decoded_images_75)\n",
    "print(\"Average PSNR for lambda 75 validation images:\", np.mean(psnr_75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For this particular task,  how did you measure how good your configuration for latent space dimensionality is? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One determinant of how good the latent space configuration is the ammount of loss. Since the loss of the model seems to be minimal, therefore the configuration is appropriate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
